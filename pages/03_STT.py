import streamlit as st, base64, io, wave, ffmpeg
from openai import OpenAI

st.set_page_config(page_title="ğŸ™ï¸ ì‹¤ì‹œê°„ STT (TURN ë¶ˆí•„ìš”)", page_icon="ğŸ™ï¸")
client = OpenAI(api_key=st.secrets["openai_api_key"])

st.title("ğŸ™ï¸ ì‹¤ì‹œê°„ ìŒì„± ì¸ì‹ (TURN ë¶ˆí•„ìš” Â· ì§€ì—°â‰ˆ1 s)")

# â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€ 1) ë¸Œë¼ìš°ì € ë…¹ìŒ + Base64 ì „ì†¡ â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€ #
b64_chunk = st.components.v1.html(
    """
<button id="rec">ğŸ¤ Start / Stop</button>
<script>
let rec=null, chunks=[];
document.getElementById("rec").onclick = async () => {
  if(rec && rec.state==="recording"){ rec.stop(); return; }           // STOP
  const stream = await navigator.mediaDevices.getUserMedia({audio:true});
  rec = new MediaRecorder(stream, {mimeType:"audio/webm"});
  rec.ondataavailable = e => {
      chunks.push(e.data);
      if(chunks.length >= 2){                                         // â‰ˆ1 s
          const blob = new Blob(chunks, {type:"audio/webm"});
          chunks = [];
          const fr = new FileReader();
          fr.onload = () => {
              const b64 = fr.result.split(',')[1];                    // data:â€¦;base64,
              Streamlit.setComponentValue(b64);                       // ğŸ”‘ Pythonìœ¼ë¡œ ì „ë‹¬
          };
          fr.readAsDataURL(blob);
      }
  };
  rec.start(500);                                                     // 0.5 s ì²­í¬
};
</script>
""",
    height=70,
)

# â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€ 2) Python â€” Base64 â†’ Whisper â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€ #
if b64_chunk:                                         # ê°’ì´ ë“¤ì–´ì˜¤ë©´
    # WebM â–¶ï¸ WAV(16 kHz mono) ë³€í™˜
    webm_bytes = base64.b64decode(b64_chunk)
    wav_bytes, _ = (
        ffmpeg
        .input("pipe:0")
        .output("pipe:1", format="wav", ac=1, ar="16k")
        .run(input=webm_bytes, capture_stdout=True, quiet=True)
    )
    # Whisper STT
    text = client.audio.transcriptions.create(
        model="whisper-1",
        file=io.BytesIO(wav_bytes),
        language="ko",
        response_format="text",
        temperature=0,
    ).strip()

    # ìë§‰ ì„¸ì…˜ ìƒíƒœ ëˆ„ì 
    st.session_state.setdefault("subs", "")
    st.session_state["subs"] += " " + text

# â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€ 3) ìë§‰ ì¶œë ¥ â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€ #
st.subheader("ìë§‰")
st.markdown(st.session_state.get("subs", "ğŸ•’ ëŒ€ê¸° ì¤‘â€¦"))
