# â†‘ íŒŒì¼ ì²«ë¨¸ë¦¬: ì¶”ê°€ import
import threading, asyncio, queue, av
from streamlit_webrtc import webrtc_streamer, AudioProcessorBase
from openai import OpenAI
import streamlit as st

# ---------- OpenAI & Streamlit ê¸°ë³¸ ì„¤ì • ----------
st.set_page_config(page_title="ğŸ™ï¸ ì‹¤ì‹œê°„ STT", page_icon="ğŸ™ï¸")
client = OpenAI(api_key=st.secrets["openai_api_key"])
st.title("ğŸ™ï¸ ì‹¤ì‹œê°„ ìŒì„± ì¸ì‹ (í•œêµ­ì–´)")

# ---------- 1) ì˜¤ë””ì˜¤ í”„ë¡œì„¸ì„œ ----------
class AudioProcessor(AudioProcessorBase):
    def __init__(self):
        self.q = queue.Queue()

    def recv_audio(self, frame: av.AudioFrame) -> av.AudioFrame:
        mono16 = frame.reformat(format="s16", layout="mono", rate=16000)
        self.q.put(mono16.planes[0].to_bytes())
        return frame


processor = webrtc_streamer(
    key="stt-demo",
    audio_processor_factory=AudioProcessor,
    media_stream_constraints={"audio": True, "video": False},
    async_processing=True,
)

# ---------- 2) ë°±ê·¸ë¼ìš´ë“œ event-loop (í•œ ë²ˆë§Œ ìƒì„±) ----------
if "bg_loop" not in st.session_state:
    st.session_state.bg_loop = asyncio.new_event_loop()
    threading.Thread(
        target=st.session_state.bg_loop.run_forever,
        daemon=True
    ).start()

# ---------- 3) STT ìŠ¤íŠ¸ë¦¬ë° ì½”ë£¨í‹´ ----------
async def transcribe_loop(audio_q: queue.Queue):
    st_placeholder = st.empty()
    aggregator = b""
    async with client.audio.transcriptions.with_stream(
        model="gpt-4o-transcribe",
        response_format="text",
        language="ko"
    ) as streamer:
        while True:
            try:
                chunk = audio_q.get(timeout=0.1)
                aggregator += chunk
                # 0.25 ì´ˆ ì´ìƒ ëª¨ìœ¼ë©´ ì „ì†¡
                if len(aggregator) > 8000:
                    await streamer.send_chunk(aggregator)
                    aggregator = b""
            except queue.Empty:
                pass
            async for text in streamer.iter_text(timeout=0):
                st_placeholder.markdown(f"ğŸ“ **{text.strip()}**")

# ---------- 4) ë§ˆì´í¬ ì¼œì§€ë©´ ì½”ë£¨í‹´ ë“±ë¡ ----------
if processor and processor.state.playing:
    if "stt_future" not in st.session_state:
        st.session_state.stt_future = asyncio.run_coroutine_threadsafe(
            transcribe_loop(processor.audio_processor.q),
            st.session_state.bg_loop
        )
    st.info("ğŸ¤ ë§ˆì´í¬ê°€ ì¼œì¡ŒìŠµë‹ˆë‹¤. ë§ì„ í•˜ë©´ ìë§‰ì´ ì‹¤ì‹œê°„ìœ¼ë¡œ ë‚˜íƒ€ë‚©ë‹ˆë‹¤.")
else:
    st.warning("â–¶ï¸ ìƒë‹¨ì˜ **Start** ë²„íŠ¼ì„ ëˆŒëŸ¬ ë§ˆì´í¬ ìŠ¤íŠ¸ë¦¼ì„ ì¼œ ì£¼ì„¸ìš”.")
