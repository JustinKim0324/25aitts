import streamlit as st
from audio_recorder_streamlit import audio_recorder
import speech_recognition as sr
import io
from pydub import AudioSegment
import tempfile
import os

# í˜ì´ì§€ ì„¤ì •
st.set_page_config(
    page_title="ì‹¤ì‹œê°„ ìŒì„± ì¸ì‹",
    page_icon="ğŸ¤",
    layout="wide"
)

# ì„¸ì…˜ ìƒíƒœ ì´ˆê¸°í™”
if 'transcribed_text' not in st.session_state:
    st.session_state.transcribed_text = ""
if 'audio_count' not in st.session_state:
    st.session_state.audio_count = 0

# ìŒì„± ì¸ì‹ í•¨ìˆ˜
def transcribe_audio(audio_bytes, language="ko-KR"):
    """ì˜¤ë””ì˜¤ ë°”ì´íŠ¸ë¥¼ í…ìŠ¤íŠ¸ë¡œ ë³€í™˜"""
    recognizer = sr.Recognizer()
    
    try:
        # ì˜¤ë””ì˜¤ ë°ì´í„°ë¥¼ ì„ì‹œ íŒŒì¼ë¡œ ì €ì¥
        with tempfile.NamedTemporaryFile(delete=False, suffix=".wav") as tmp_file:
            tmp_file.write(audio_bytes)
            tmp_file_path = tmp_file.name
        
        # WAV íŒŒì¼ë¡œ ë³€í™˜ (audio_recorderëŠ” wav í˜•ì‹ìœ¼ë¡œ ë…¹ìŒ)
        audio = AudioSegment.from_wav(io.BytesIO(audio_bytes))
        audio.export(tmp_file_path, format="wav")
        
        # ìŒì„± ì¸ì‹
        with sr.AudioFile(tmp_file_path) as source:
            audio_data = recognizer.record(source)
            text = recognizer.recognize_google(audio_data, language=language)
        
        # ì„ì‹œ íŒŒì¼ ì‚­ì œ
        os.unlink(tmp_file_path)
        
        return text
    
    except sr.UnknownValueError:
        return "ìŒì„±ì„ ì¸ì‹í•  ìˆ˜ ì—†ìŠµë‹ˆë‹¤."
    except sr.RequestError as e:
        return f"ìŒì„± ì¸ì‹ ì„œë¹„ìŠ¤ ì˜¤ë¥˜: {e}"
    except Exception as e:
        return f"ì˜¤ë¥˜ ë°œìƒ: {e}"

# ë©”ì¸ ì•±
def main():
    st.title("ğŸ¤ ì‹¤ì‹œê°„ ìŒì„± ì¸ì‹ (Real-time STT)")
    st.markdown("ë…¹ìŒ ë²„íŠ¼ì„ í´ë¦­í•˜ê³  ë§ì”€í•˜ì„¸ìš”. ë…¹ìŒì´ ëë‚˜ë©´ ìë™ìœ¼ë¡œ í…ìŠ¤íŠ¸ë¡œ ë³€í™˜ë©ë‹ˆë‹¤.")
    
    # ì‚¬ì´ë“œë°” ì„¤ì •
    with st.sidebar:
        st.header("âš™ï¸ ì„¤ì •")
        
        # ì–¸ì–´ ì„ íƒ
        language = st.selectbox(
            "ì¸ì‹ ì–¸ì–´",
            ["í•œêµ­ì–´", "ì˜ì–´", "ì¼ë³¸ì–´", "ì¤‘êµ­ì–´", "ìŠ¤í˜ì¸ì–´", "í”„ë‘ìŠ¤ì–´"],
            index=0
        )
        
        language_map = {
            "í•œêµ­ì–´": "ko-KR",
            "ì˜ì–´": "en-US",
            "ì¼ë³¸ì–´": "ja-JP",
            "ì¤‘êµ­ì–´": "zh-CN",
            "ìŠ¤í˜ì¸ì–´": "es-ES",
            "í”„ë‘ìŠ¤ì–´": "fr-FR"
        }
        
        selected_language = language_map[language]
        
        # ë…¹ìŒ ì„¤ì •
        st.subheader("ğŸ™ï¸ ë…¹ìŒ ì„¤ì •")
        auto_submit = st.checkbox("ìë™ ì œì¶œ", value=True, help="ë…¹ìŒì´ ëë‚˜ë©´ ìë™ìœ¼ë¡œ í…ìŠ¤íŠ¸ ë³€í™˜")
        
        # ì‚¬ìš© ì•ˆë‚´
        st.markdown("### ğŸ“– ì‚¬ìš© ë°©ë²•")
        st.markdown("""
        1. ğŸ¤ ë²„íŠ¼ì„ í´ë¦­í•˜ì—¬ ë…¹ìŒì„ ì‹œì‘í•©ë‹ˆë‹¤
        2. ë§ì”€ì„ ë§ˆì¹˜ë©´ ë‹¤ì‹œ í´ë¦­í•˜ì—¬ ë…¹ìŒì„ ì¤‘ì§€í•©ë‹ˆë‹¤
        3. ìë™ìœ¼ë¡œ í…ìŠ¤íŠ¸ë¡œ ë³€í™˜ë©ë‹ˆë‹¤
        4. ê³„ì†í•´ì„œ ë…¹ìŒí•˜ë©´ í…ìŠ¤íŠ¸ê°€ ëˆ„ì ë©ë‹ˆë‹¤
        """)
        
        # í…ìŠ¤íŠ¸ ê´€ë¦¬
        st.markdown("### ğŸ“ í…ìŠ¤íŠ¸ ê´€ë¦¬")
        if st.button("ğŸ—‘ï¸ ì „ì²´ í…ìŠ¤íŠ¸ ì§€ìš°ê¸°", use_container_width=True):
            st.session_state.transcribed_text = ""
            st.rerun()
    
    # ë©”ì¸ ì»¨í…ì¸ 
    col1, col2 = st.columns([1, 2])
    
    with col1:
        st.header("ğŸ™ï¸ ìŒì„± ì…ë ¥")
        
        # ì˜¤ë””ì˜¤ ë ˆì½”ë”
        st.markdown("ì•„ë˜ ë²„íŠ¼ì„ í´ë¦­í•˜ì—¬ ë…¹ìŒí•˜ì„¸ìš”:")
        
        audio_bytes = audio_recorder(
            text="í´ë¦­í•˜ì—¬ ë…¹ìŒ ì‹œì‘/ì¤‘ì§€",
            recording_color="#e74c3c",
            neutral_color="#2c3e50",
            icon_name="microphone",
            icon_size="3x",
            auto_start=False,
            pause_threshold=2.0,
            sample_rate=16000,
            key=f"audio_recorder_{st.session_state.audio_count}"
        )
        
        # ì˜¤ë””ì˜¤ê°€ ë…¹ìŒë˜ë©´ ì²˜ë¦¬
        if audio_bytes:
            st.audio(audio_bytes, format="audio/wav")
            
            if auto_submit:
                with st.spinner("ìŒì„±ì„ í…ìŠ¤íŠ¸ë¡œ ë³€í™˜ ì¤‘..."):
                    text = transcribe_audio(audio_bytes, selected_language)
                    if text and text not in ["ìŒì„±ì„ ì¸ì‹í•  ìˆ˜ ì—†ìŠµë‹ˆë‹¤.", "ìŒì„± ì¸ì‹ ì„œë¹„ìŠ¤ ì˜¤ë¥˜"]:
                        st.session_state.transcribed_text += text + " "
                        st.session_state.audio_count += 1
                        st.success("âœ… ë³€í™˜ ì™„ë£Œ!")
                        st.rerun()
                    else:
                        st.warning(text)
        
        # ìˆ˜ë™ ë³€í™˜ ë²„íŠ¼
        if not auto_submit and audio_bytes:
            if st.button("ğŸ“ í…ìŠ¤íŠ¸ë¡œ ë³€í™˜", type="primary", use_container_width=True):
                with st.spinner("ìŒì„±ì„ í…ìŠ¤íŠ¸ë¡œ ë³€í™˜ ì¤‘..."):
                    text = transcribe_audio(audio_bytes, selected_language)
                    if text:
                        st.session_state.transcribed_text += text + " "
                        st.success("âœ… ë³€í™˜ ì™„ë£Œ!")
                        st.rerun()
    
    with col2:
        st.header("ğŸ“ ì¸ì‹ëœ í…ìŠ¤íŠ¸")
        
        # ì‹¤ì‹œê°„ í…ìŠ¤íŠ¸ í‘œì‹œ
        text_area = st.text_area(
            "ëˆ„ì ëœ í…ìŠ¤íŠ¸:",
            value=st.session_state.transcribed_text,
            height=400,
            key="main_text_area"
        )
        
        # ë²„íŠ¼ ê·¸ë£¹
        col_btn1, col_btn2, col_btn3 = st.columns(3)
        
        with col_btn1:
            # ë³µì‚¬ ë²„íŠ¼ (í´ë¦½ë³´ë“œ ë³µì‚¬ëŠ” JavaScript í•„ìš”)
            if st.button("ğŸ“‹ ë³µì‚¬", use_container_width=True):
                st.info("í…ìŠ¤íŠ¸ë¥¼ ì„ íƒí•˜ê³  Ctrl+C (ë˜ëŠ” Cmd+C)ë¥¼ ëˆŒëŸ¬ ë³µì‚¬í•˜ì„¸ìš”")
        
        with col_btn2:
            # í¸ì§‘ ëª¨ë“œ
            if st.button("âœï¸ í¸ì§‘", use_container_width=True):
                st.session_state.transcribed_text = text_area
                st.success("í…ìŠ¤íŠ¸ê°€ ì—…ë°ì´íŠ¸ë˜ì—ˆìŠµë‹ˆë‹¤!")
        
        with col_btn3:
            # ë‹¤ìš´ë¡œë“œ ë²„íŠ¼
            if st.session_state.transcribed_text:
                st.download_button(
                    label="ğŸ“¥ ë‹¤ìš´ë¡œë“œ",
                    data=st.session_state.transcribed_text,
                    file_name="transcript.txt",
                    mime="text/plain",
                    use_container_width=True
                )
        
        # í†µê³„ ì •ë³´
        if st.session_state.transcribed_text:
            st.markdown("### ğŸ“Š í†µê³„")
            word_count = len(st.session_state.transcribed_text.split())
            char_count = len(st.session_state.transcribed_text)
            
            metric_col1, metric_col2 = st.columns(2)
            with metric_col1:
                st.metric("ë‹¨ì–´ ìˆ˜", f"{word_count:,}")
            with metric_col2:
                st.metric("ë¬¸ì ìˆ˜", f"{char_count:,}")
    
    # í‘¸í„°
    st.markdown("---")
    st.markdown(
        """
        <div style='text-align: center'>
            <p>Google Speech Recognition APIë¥¼ ì‚¬ìš©í•©ë‹ˆë‹¤</p>
            <p>Made with â¤ï¸ using Streamlit</p>
        </div>
        """,
        unsafe_allow_html=True
    )

if __name__ == "__main__":
    main()
